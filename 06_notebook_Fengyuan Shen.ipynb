{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0u0s4Ev-8oqj"
      },
      "source": [
        "# DS 542 Notebook 6\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SE706BcH8vA5"
      },
      "source": [
        "## Download Data\n",
        "\n",
        "The following cells download the UCI Abalone data set.\n",
        "You should not need to modify any of these cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZmbh4jm7Jgd",
        "outputId": "ab67f78c-11f3-4587-dd94-24c9da1aa2ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-09-28 19:13:08--  https://archive.ics.uci.edu/static/public/1/abalone.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified\n",
            "Saving to: ‘abalone.zip’\n",
            "\n",
            "abalone.zip             [ <=>                ]  54.06K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-09-28 19:13:08 (404 KB/s) - ‘abalone.zip’ saved [55357]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://archive.ics.uci.edu/static/public/1/abalone.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnE9o9mz7Qlh",
        "outputId": "6e452d6c-f898-463d-a892-df25207e7e75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  abalone.zip\n",
            "  inflating: Index                   \n",
            "  inflating: abalone.data            \n",
            "  inflating: abalone.names           \n"
          ]
        }
      ],
      "source": [
        "!unzip abalone.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BU97NROU7UNy",
        "outputId": "f03de4d1-f505-41b4-eb3f-6617da530c21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1. Title of Database: Abalone data\n",
            "\n",
            "2. Sources:\n",
            "\n",
            "   (a) Original owners of database:\n",
            "\tMarine Resources Division\n",
            "\tMarine Research Laboratories - Taroona\n",
            "\tDepartment of Primary Industry and Fisheries, Tasmania\n",
            "\tGPO Box 619F, Hobart, Tasmania 7001, Australia\n",
            "\t(contact: Warwick Nash +61 02 277277, wnash@dpi.tas.gov.au)\n",
            "\n",
            "   (b) Donor of database:\n",
            "\tSam Waugh (Sam.Waugh@cs.utas.edu.au)\n",
            "\tDepartment of Computer Science, University of Tasmania\n",
            "\tGPO Box 252C, Hobart, Tasmania 7001, Australia\n",
            "\n",
            "   (c) Date received: December 1995\n",
            "\n",
            "\n",
            "3. Past Usage:\n",
            "\n",
            "   Sam Waugh (1995) \"Extending and benchmarking Cascade-Correlation\", PhD\n",
            "   thesis, Computer Science Department, University of Tasmania.\n",
            "\n",
            "   -- Test set performance (final 1044 examples, first 3133 used for training):\n",
            "\t24.86% Cascade-Correlation (no hidden nodes)\n",
            "\t26.25% Cascade-Correlation (5 hidden nodes)\n",
            "\t21.5%  C4.5\n",
            "\t 0.0%  Linear Discriminate Analysis\n",
            "\t 3.57% k=5 Nearest Neighbour\n",
            "      (Problem encoded as a classification task)\n",
            "\n",
            "   -- Data set samples are highly overlapped.  Further information is required\n",
            "\tto separate completely using affine combinations.  Other restrictions\n",
            "\tto data set examined.\n",
            "\n",
            "   David Clark, Zoltan Schreter, Anthony Adams \"A Quantitative Comparison of\n",
            "   Dystal and Backpropagation\", submitted to the Australian Conference on\n",
            "   Neural Networks (ACNN'96). Data set treated as a 3-category classification\n",
            "   problem (grouping ring classes 1-8, 9 and 10, and 11 on).\n",
            "\n",
            "   -- Test set performance (3133 training, 1044 testing as above):\n",
            "\t64%    Backprop\n",
            "\t55%    Dystal\n",
            "   -- Previous work (Waugh, 1995) on same data set:\n",
            "\t61.40% Cascade-Correlation (no hidden nodes)\n",
            "\t65.61% Cascade-Correlation (5 hidden nodes)\n",
            "\t59.2%  C4.5\n",
            "\t32.57% Linear Discriminate Analysis\n",
            "\t62.46% k=5 Nearest Neighbour\n",
            "\n",
            "\n",
            "4. Relevant Information Paragraph:\n",
            "\n",
            "   Predicting the age of abalone from physical measurements.  The age of\n",
            "   abalone is determined by cutting the shell through the cone, staining it,\n",
            "   and counting the number of rings through a microscope -- a boring and\n",
            "   time-consuming task.  Other measurements, which are easier to obtain, are\n",
            "   used to predict the age.  Further information, such as weather patterns\n",
            "   and location (hence food availability) may be required to solve the problem.\n",
            "\n",
            "   From the original data examples with missing values were removed (the\n",
            "   majority having the predicted value missing), and the ranges of the\n",
            "   continuous values have been scaled for use with an ANN (by dividing by 200).\n",
            "\n",
            "   Data comes from an original (non-machine-learning) study:\n",
            "\n",
            "\tWarwick J Nash, Tracy L Sellers, Simon R Talbot, Andrew J Cawthorn and\n",
            "\tWes B Ford (1994) \"The Population Biology of Abalone (_Haliotis_\n",
            "\tspecies) in Tasmania. I. Blacklip Abalone (_H. rubra_) from the North\n",
            "\tCoast and Islands of Bass Strait\", Sea Fisheries Division, Technical\n",
            "\tReport No. 48 (ISSN 1034-3288)\n",
            "\n",
            "\n",
            "5. Number of Instances: 4177\n",
            "\n",
            "\n",
            "6. Number of Attributes: 8\n",
            "\n",
            "\n",
            "7. Attribute information:\n",
            "\n",
            "   Given is the attribute name, attribute type, the measurement unit and a\n",
            "   brief description.  The number of rings is the value to predict: either\n",
            "   as a continuous value or as a classification problem.\n",
            "\n",
            "\tName\t\tData Type\tMeas.\tDescription\n",
            "\t----\t\t---------\t-----\t-----------\n",
            "\tSex\t\tnominal\t\t\tM, F, and I (infant)\n",
            "\tLength\t\tcontinuous\tmm\tLongest shell measurement\n",
            "\tDiameter\tcontinuous\tmm\tperpendicular to length\n",
            "\tHeight\t\tcontinuous\tmm\twith meat in shell\n",
            "\tWhole weight\tcontinuous\tgrams\twhole abalone\n",
            "\tShucked weight\tcontinuous\tgrams\tweight of meat\n",
            "\tViscera weight\tcontinuous\tgrams\tgut weight (after bleeding)\n",
            "\tShell weight\tcontinuous\tgrams\tafter being dried\n",
            "\tRings\t\tinteger\t\t\t+1.5 gives the age in years\n",
            "\n",
            "   Statistics for numeric domains:\n",
            "\n",
            "\t\tLength\tDiam\tHeight\tWhole\tShucked\tViscera\tShell\tRings\n",
            "\tMin\t0.075\t0.055\t0.000\t0.002\t0.001\t0.001\t0.002\t    1\n",
            "\tMax\t0.815\t0.650\t1.130\t2.826\t1.488\t0.760\t1.005\t   29\n",
            "\tMean\t0.524\t0.408\t0.140\t0.829\t0.359\t0.181\t0.239\t9.934\n",
            "\tSD\t0.120\t0.099\t0.042\t0.490\t0.222\t0.110\t0.139\t3.224\n",
            "\tCorrel\t0.557\t0.575\t0.557\t0.540\t0.421\t0.504\t0.628\t  1.0\n",
            "\n",
            "\n",
            "8. Missing Attribute Values: None\n",
            "\n",
            "\n",
            "9. Class Distribution:\n",
            "\n",
            "\tClass\tExamples\n",
            "\t-----\t--------\n",
            "\t1\t1\n",
            "\t2\t1\n",
            "\t3\t15\n",
            "\t4\t57\n",
            "\t5\t115\n",
            "\t6\t259\n",
            "\t7\t391\n",
            "\t8\t568\n",
            "\t9\t689\n",
            "\t10\t634\n",
            "\t11\t487\n",
            "\t12\t267\n",
            "\t13\t203\n",
            "\t14\t126\n",
            "\t15\t103\n",
            "\t16\t67\n",
            "\t17\t58\n",
            "\t18\t42\n",
            "\t19\t32\n",
            "\t20\t26\n",
            "\t21\t14\n",
            "\t22\t6\n",
            "\t23\t9\n",
            "\t24\t2\n",
            "\t25\t1\n",
            "\t26\t1\n",
            "\t27\t2\n",
            "\t29\t1\n",
            "\t-----\t----\n",
            "\tTotal\t4177\n"
          ]
        }
      ],
      "source": [
        "!cat abalone.names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pxdc0PRe9ctB"
      },
      "source": [
        "## Prepare Data\n",
        "\n",
        "This section reads the data set and converts it to PyTorch tensors.\n",
        "You probably do not need to modify this section."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EKqY2zGfAn7I"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0EliOyJs7n6Y"
      },
      "outputs": [],
      "source": [
        "abalone_X = []\n",
        "abalone_Y = []\n",
        "with open('abalone.data') as abalone_file:\n",
        "    for line in abalone_file:\n",
        "        line = line.rstrip(\"\\n\")\n",
        "        line = line.split(\",\")\n",
        "\n",
        "        # drop initial sex column\n",
        "        line = line[1:]\n",
        "\n",
        "        # convert from strings to numbers\n",
        "        line = [float(v) for v in line]\n",
        "\n",
        "        abalone_X.append(line[:-1])\n",
        "        abalone_Y.append(line[-1])\n",
        "\n",
        "abalone_X = np.array(abalone_X)\n",
        "abalone_Y = np.array(abalone_Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1W-QTMS7A3w0",
        "outputId": "49fb1475-c173-4f79-9a58-7b77e72ea2cd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# GPU configuration\n",
        "\n",
        "def to_gpu(t):\n",
        "    if torch.cuda.is_available():\n",
        "        return t.cuda()\n",
        "    return t\n",
        "\n",
        "def to_numpy(t):\n",
        "    return t.detach().cpu().numpy()\n",
        "\n",
        "device = to_gpu(torch.ones(1,1)).device\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mon Sep 30 21:41:59 2024       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla V100-SXM2-16GB           On  |   00000000:18:00.0 Off |                    0 |\n",
            "| N/A   46C    P0             62W /  300W |     312MiB /  16384MiB |      0%   E. Process |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "|   1  Tesla V100-SXM2-16GB           On  |   00000000:3B:00.0 Off |                    0 |\n",
            "| N/A   58C    P0            184W /  300W |    9978MiB /  16384MiB |     89%   E. Process |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "|   2  Tesla V100-SXM2-16GB           On  |   00000000:86:00.0 Off |                    0 |\n",
            "| N/A   36C    P0             44W /  300W |       1MiB /  16384MiB |      0%   E. Process |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "|   3  Tesla V100-SXM2-16GB           On  |   00000000:AF:00.0 Off |                    0 |\n",
            "| N/A   38C    P0             45W /  300W |       1MiB /  16384MiB |      0%   E. Process |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|    0   N/A  N/A    658153      C   ...thon3/3.10.5/install/bin/python3.10        308MiB |\n",
            "|    1   N/A  N/A    626223      C   python                                       9974MiB |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VAfntp_-AyMn"
      },
      "outputs": [],
      "source": [
        "# switch from NumPy arrays to Torch tensors\n",
        "\n",
        "abalone_X = torch.tensor(abalone_X, device=device)\n",
        "abalone_Y = torch.tensor(abalone_Y, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQEag8JZBHA9",
        "outputId": "012c894a-5c88-4c5e-8d86-6ec730d60bb0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.4550, 0.3650, 0.0950,  ..., 0.2245, 0.1010, 0.1500],\n",
              "        [0.3500, 0.2650, 0.0900,  ..., 0.0995, 0.0485, 0.0700],\n",
              "        [0.5300, 0.4200, 0.1350,  ..., 0.2565, 0.1415, 0.2100],\n",
              "        ...,\n",
              "        [0.6000, 0.4750, 0.2050,  ..., 0.5255, 0.2875, 0.3080],\n",
              "        [0.6250, 0.4850, 0.1500,  ..., 0.5310, 0.2610, 0.2960],\n",
              "        [0.7100, 0.5550, 0.1950,  ..., 0.9455, 0.3765, 0.4950]],\n",
              "       device='cuda:0', dtype=torch.float64)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "abalone_X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_P9YXC30BLD6",
        "outputId": "92f54ce2-f066-4aba-cc9c-bad7018e4f20"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4177, 7])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "abalone_X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFNB5RSNBMbJ",
        "outputId": "1f23b764-5668-4f82-c1d6-277532eb9138"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([15.,  7.,  9.,  ...,  9., 10., 12.], device='cuda:0',\n",
              "       dtype=torch.float64)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "abalone_Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZHC3Fu1BNuL",
        "outputId": "19ebc9ec-7974-4916-a708-dca3a42cce57"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4177])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "abalone_Y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLK6KrMQ87h6"
      },
      "source": [
        "## Problem 1 - Linear Regression\n",
        "\n",
        "Use PyTorch to implement linear regression of the abalone Rings column saved in `abalone_Y` using the columns in `abalone_X` as inputs.\n",
        "Train your linear model using gradient descent as described in lecture.\n",
        "\n",
        "You can freely use code from the [example training notebook shared in class](https://colab.research.google.com/drive/1xWo_rF0exGdewtaMZP5LNBKJolxUVt8u?usp=sharing).\n",
        "This model should be much simpler than that example - in particular, you do not not need (and should not have) the Fourier features, hidden layers, and activation functions.\n",
        "\n",
        "Feel free to add extra cells as you feel appropriate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "gu_4VZNM8_7u"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [100/1000], Loss: 45.1000\n",
            "Epoch [200/1000], Loss: 21.6714\n",
            "Epoch [300/1000], Loss: 13.1931\n",
            "Epoch [400/1000], Loss: 10.0962\n",
            "Epoch [500/1000], Loss: 8.9381\n",
            "Epoch [600/1000], Loss: 8.4799\n",
            "Epoch [700/1000], Loss: 8.2760\n",
            "Epoch [800/1000], Loss: 8.1658\n",
            "Epoch [900/1000], Loss: 8.0914\n",
            "Epoch [1000/1000], Loss: 8.0318\n"
          ]
        }
      ],
      "source": [
        "# BUILD AND TRAIN YOUR LINEAR MODEL HERE\n",
        "\n",
        "# Linear Regression Model without hidden layers and activation functions\n",
        "class LinearRegressionModel(torch.nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super(LinearRegressionModel, self).__init__()\n",
        "        self.linear = torch.nn.Linear(input_size, output_size)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "# Reshape abalone_Y to be a column vector\n",
        "abalone_Y = abalone_Y.view(-1, 1)\n",
        "\n",
        "# Input and Output size\n",
        "input_size = abalone_X.shape[1] # 7 features\n",
        "output_size = abalone_Y.shape[1] # 1 feature\n",
        "\n",
        "# Initialization\n",
        "model = LinearRegressionModel(input_size, output_size).to(device)\n",
        "\n",
        "criterion = torch.nn.MSELoss() # Loss function (Mean Squared Error)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001) # Optimizer (Stochastic Gradient Descent)\n",
        "\n",
        "# Training\n",
        "num_epochs = 1000\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Forward pass\n",
        "    outputs = model(abalone_X.float())\n",
        "    \n",
        "    # Compute the loss\n",
        "    loss = criterion(outputs, abalone_Y.float())\n",
        "    \n",
        "    # Zero gradients, perform a backward pass, and update weights\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    if (epoch+1) % 100 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "eCcX2NJY--rS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Linear Model Coefficients: tensor([[2.3402, 1.9282, 0.7325, 3.2595, 1.4453, 0.5807, 0.7253]],\n",
            "       device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "# PRINT YOUR LINEAR MODEL COEFFICIENTS HERE\n",
        "print(\"Linear Model Coefficients:\", model.linear.weight.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "_deHI3JA_Fh-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Linear Bias: tensor([4.0298], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "# PRINT YOUR LINEAR BIAS HERE.\n",
        "print(\"Linear Bias:\", model.linear.bias.data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G96dYHoJ-gDj"
      },
      "source": [
        "## Problem 2 - A Better Model\n",
        "\n",
        "Build and train a separate model using PyTorch using at least one hidden layer.\n",
        "Then answer the questions below.\n",
        "\n",
        "Again, you can freely use code from the [example training notebook shared in class](https://colab.research.google.com/drive/1xWo_rF0exGdewtaMZP5LNBKJolxUVt8u?usp=sharing).\n",
        "You should not need the Fourier features for this particular model.\n",
        "\n",
        "Feel free to add extra cells as you feel appropriate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Q6dRkXl1_h1j"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [100/1000], Loss: 7.0799\n",
            "Epoch [200/1000], Loss: 5.9763\n",
            "Epoch [300/1000], Loss: 4.7600\n",
            "Epoch [400/1000], Loss: 4.4921\n",
            "Epoch [500/1000], Loss: 4.4184\n",
            "Epoch [600/1000], Loss: 4.3759\n",
            "Epoch [700/1000], Loss: 4.3434\n",
            "Epoch [800/1000], Loss: 4.2757\n",
            "Epoch [900/1000], Loss: 4.2269\n",
            "Epoch [1000/1000], Loss: 4.1941\n"
          ]
        }
      ],
      "source": [
        "# BUILD AND TRAIN YOUR SECOND MODEL HERE\n",
        "\n",
        "# Neural Network with three hidden layers\n",
        "class NeuralNetworkModel(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_size1, hidden_size2, hidden_size3, output_size):\n",
        "        super(NeuralNetworkModel, self).__init__()\n",
        "        self.fc1 = torch.nn.Linear(input_size, hidden_size1)  # First hidden layer\n",
        "        self.fc2 = torch.nn.Linear(hidden_size1, hidden_size2) # Second hidden layer\n",
        "        self.fc3 = torch.nn.Linear(hidden_size2, hidden_size3) # Third hidden layer\n",
        "        self.fc4 = torch.nn.Linear(hidden_size3, output_size)  # Output layer\n",
        "        self.relu = torch.nn.ReLU()  # Activation function\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)  # First hidden layer\n",
        "        x = self.relu(x) # ReLU activation\n",
        "        x = self.fc2(x)  # Second hidden layer\n",
        "        x = self.relu(x) # ReLU activation\n",
        "        x = self.fc3(x)  # Third hidden layer\n",
        "        x = self.relu(x) # ReLU activation\n",
        "        x = self.fc4(x)  # Output layer\n",
        "        return x\n",
        "\n",
        "# Reshape abalone_Y to be a column vector\n",
        "abalone_Y = abalone_Y.view(-1, 1)\n",
        "\n",
        "# Input , Hidden, and Output size\n",
        "input_size = abalone_X.shape[1] # 7 features\n",
        "hidden_size1 = 512\n",
        "hidden_size2 = 128\n",
        "hidden_size3 = 32\n",
        "output_size = abalone_Y.shape[1] # 1 feature\n",
        "\n",
        "# Initialization\n",
        "model = NeuralNetworkModel(input_size, hidden_size1, hidden_size2, hidden_size3, output_size).to(device)\n",
        "\n",
        "criterion = torch.nn.MSELoss() # Loss function (Mean Squared Error)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) # Optimizer (Adaptive Moment Estimation)\n",
        "\n",
        "# Training\n",
        "num_epochs = 1000\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Forward pass\n",
        "    outputs = model(abalone_X.float())\n",
        "    \n",
        "    # Compute the loss\n",
        "    loss = criterion(outputs, abalone_Y.float())\n",
        "    \n",
        "    # Zero gradients, perform a backward pass, and update weights\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    if (epoch+1) % 100 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwi0eFpD_-PZ"
      },
      "source": [
        "Describe the second model that you built.\n",
        "Include the number and widths of the hidden layers, the activation functions, and anything else that you deem important."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyJy2E0JASK0"
      },
      "source": [
        "YOUR ANSWER HERE.\n",
        "\n",
        "**Model Description:**\n",
        "1. **Input Layer**: 7 features.\n",
        "2. **Hidden Layers**: Three hidden layers, each structured as follows:\n",
        "   - **First hidden layer**: 512 neurons, followed by the ReLU activation function.\n",
        "   - **Second hidden layer**: 128 neurons, followed by the ReLU activation function.\n",
        "   - **Third hidden layer**: 32 neurons, followed by the ReLU activation function.\n",
        "3. **Activation Function**: ReLU (Rectified Linear Unit).\n",
        "4. **Output Layer**: 1 neuron, representing the predicted abalone Rings.\n",
        "5. **Optimizer**: Adam (Adaptive Moment Estimation).\n",
        "6. **Learning Rate**: 0.001.\n",
        "7. **Loss Function**: MSE (Mean Squared Error)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWvK1LSDAT51"
      },
      "source": [
        "What loss value did your second model achieve?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "g-eyHskRAXN5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final Loss: 4.1941\n"
          ]
        }
      ],
      "source": [
        "# PRINT YOUR LOSS HERE\n",
        "print(f'Final Loss: {loss.item():.4f}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
